# -*- coding: utf-8 -*-
"""OCR_Searching_for_specific_terms.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Iy5I6n_5DWRUp_ezZuhr3bqXSU3K2Xyd
"""

!sudo apt install tesseract-ocr
!pip install pytesseract

!mkdir tessdata
!wget -O ./tessdata/por.traineddata https://github.com/tesseract-ocr/tessdata/blob/main/por.traineddata?raw=true

import pytesseract
from pytesseract import Output
import numpy as np
import cv2
import os
import re
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow
from PIL import ImageFont, ImageDraw, Image

from google.colab import drive
drive.mount('/content/gdrive')

!cp -R /content/gdrive/MyDrive/Cursos\ -\ recursos/OCR\ with\ Python/Images/Images\ Project\ 1/ images/

directory_imgs = "images/"
paths = [os.path.join(directory_imgs, f) for f in os.listdir(directory_imgs)]
print(paths)

def show_img(img):
  fig = plt.gcf()
  fig.set_size_inches(20, 10)
  plt.axis("off")
  plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
  plt.show()

for image in paths:
  image = cv2.imread(image)
  show_img(image)

config_tesseract = "--tessdata-dir tessdata"

def tesseract_ocr(img, config_tesseract):
  text = pytesseract.image_to_string(img, lang='por', config=config_tesseract)
  return text

full_text = ''
txt_file = 'results_ocr.txt'

for image in paths:
  #print(image)
  img = cv2.imread(image)
  file_image = os.path.split(image)[-1]
  #print(file_image)
  file_image_separate = '================\n' + str(file_image)
  #print(file_image_separate)
  full_text = full_text + file_image_separate + '\n'

  text = tesseract_ocr(img, config_tesseract)
  #print(text)
  full_text = full_text + text

full_text

file_txt = open(txt_file, 'w+')
file_txt.write(full_text + '\n')
file_txt.close()

term_search = 'computador' # computer

with open('/content/results_ocr.txt') as f:
  results = [i.start() for i in re.finditer(term_search, f.read())]

results

len(results)

for image in paths:
  #print(image)
  img = cv2.imread(image)
  file_img = os.path.split(image)[-1]
  print('==================\n' + str(file_img))
  text = tesseract_ocr(img, config_tesseract)
  results = [i.start() for i in re.finditer(term_search, text)]
  print('Number of times the term {} appears: {}'.format(term_search, len(results)))
  print('\n')

import spacy

"""> Update in 2023: for more recent spacy versions, now it's necessary to change the name of the package, from:
  * `pt` to `pt_core_news_sm`
  * `en` to `en_core_web_sm`

> This change is required in the *download command* below and also in the `spacy.load()` parameter
"""

!python -m spacy download pt_core_news_sm

!python -m spacy download en_core_web_sm

nlp_en = spacy.load('en_core_web_sm')

print(spacy.lang.en.stop_words.STOP_WORDS)

len(spacy.lang.en.stop_words.STOP_WORDS)

nlp = spacy.load('pt_core_news_sm')

stop_words = spacy.lang.pt.stop_words.STOP_WORDS
print(stop_words)

len(stop_words)

def preprocessing(text):
  text = text.lower()

  document = nlp(text)
  tokens_list = []
  for token in document:
    #print(token)
    tokens_list.append(token.text)
  #print(tokens_list)

  tokens = [word for word in tokens_list if word not in stop_words]
  #print(tokens)
  tokens = ' '.join([str(element) for element in tokens])
  #print(tokens)
  return tokens

preprocessing('Note que, se a máscara for simétrica as operações de correlação')

processed_full_text = preprocessing(full_text)

len(full_text), len(processed_full_text)

9586 - 8944

from wordcloud import WordCloud
plt.figure(figsize=(20,10))
plt.imshow(WordCloud().generate(full_text)); # of, what, the -> stopwords

from wordcloud import WordCloud
plt.figure(figsize=(20,10))
plt.imshow(WordCloud().generate(processed_full_text));

document = nlp(processed_full_text)

from spacy import displacy
displacy.render(document, style = 'ent', jupyter = True)

for entity in document.ents:
  if entity.label_ == 'PER':
    print(entity.text, entity.label_)

font = '/content/calibri.ttf'

def write_text(text, x, y, img, font, color=(50, 50, 255), font_size=16):
  font = ImageFont.truetype(font, font_size)
  img_pil = Image.fromarray(img)
  draw = ImageDraw.Draw(img_pil)
  draw.text((x, y-font_size), text, font = font, fill = color)
  img = np.array(img_pil)

  return img

min_conf = 30

def box(i, result, img, color=(255, 100, 0)):
  x = result["left"][i]
  y = result["top"][i]
  w = result["width"][i]
  h = result["height"][i]

  cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)

  return x, y, img

def ocr_process_image(img, term_search, config_tesseract, min_conf):
  result = pytesseract.image_to_data(img, config=config_tesseract, lang='por', output_type=Output.DICT)
  number_of_times = 0
  for i in range(0, len(result['text'])):
    confidence = int(result['conf'][i])
    if confidence > min_conf:
      text = result['text'][i]
      if term_search.lower() in text.lower():
        x, y, img = box(i, result, img, (0,0,255))
        img = write_text(text, x, y, img, font, (50,50,225), 14)
        number_of_times += 1
  return img, number_of_times

term_search = 'computador' # computer
for image in paths:
  #print(image)
  img = cv2.imread(image)
  img_original = img.copy()
  file_image = os.path.split(image)[-1]
  print('=================\n' + str(file_image))

  img, number_of_times = ocr_process_image(img, term_search, config_tesseract, min_conf)
  print('Number of times term {} appears in {}: {}'.format(term_search, file_image, number_of_times))
  print('\n')
  show_img(img)

term_search = 'sopa' # soup

os.makedirs('processed_images', exist_ok = True)

for image in paths:
  #print(image)
  img = cv2.imread(image)
  img_original = img.copy()
  file_image = os.path.split(image)[-1]
  img, number_of_times = ocr_process_image(img, term_search, config_tesseract, min_conf)
  if number_of_times > 0:
    show_img(img)
    new_file_image = 'processed_' + file_image
    new_image = '/content/processed_images/' + str(new_file_image)
    cv2.imwrite(new_image, img)